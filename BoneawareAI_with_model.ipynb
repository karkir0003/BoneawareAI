{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CHWhyuzyfvZ"
      },
      "source": [
        "# BoneawareAI\n",
        "\n",
        "By: Karthik Subramanian, Charles Green, Sai Anurag Pichika, Saarang Prabhuram\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFJ0ozK8yp3V"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fFVquhuCVrq",
        "outputId": "31c3936a-8c5b-41bb-a3f6-e81302c30ea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkDj-6n-EMYa",
        "outputId": "016cef28-0cc5-4a64-b7e5-2b049631b233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyyaml==5.4.1\n",
            "  Using cached PyYAML-5.4.1.tar.gz (175 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.35.65)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.65 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.35.65)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.10.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.65->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.65->boto3) (2.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.65->boto3) (1.16.0)\n",
            "Requirement already satisfied: configparser in /usr/local/lib/python3.10/dist-packages (7.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyyaml==5.4.1\n",
        "!pip install boto3\n",
        "!pip install configparser\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "It7_Rq3X4g3z",
        "outputId": "10bffc82-8fc0-4b4b-ba80-f55d287bfe3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/BoneawareAI'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import os\n",
        "PROJECT_PATH = 'BoneawareAI'\n",
        "GOOGLE_DRIVE_PATH = f'/content/drive/MyDrive/{PROJECT_PATH}'\n",
        "os.chdir(GOOGLE_DRIVE_PATH)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1w70X5avjfR1"
      },
      "outputs": [],
      "source": [
        "# make sure you run this cell so that Boneaware src path is recognized\n",
        "import sys\n",
        "sys.path.append(GOOGLE_DRIVE_PATH) # this is important for the imports in the .py files to work\n",
        "sys.path.append(os.path.join(GOOGLE_DRIVE_PATH, 'src'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGVUtueX353J"
      },
      "source": [
        "## Data Preprocessing\n",
        "Get the dataset, perform data augmentation to get finalized MURA dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIU_T5hM3-YD",
        "outputId": "fc75a920-a02a-4727-ed55-8bb5b9baaa2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File downloaded successfully to datasets/MURA-v1.1.zip\n",
            "successfully unzipped the file at path /content/drive/MyDrive/BoneawareAI/datasets/MURA-v1.1.zip\n"
          ]
        }
      ],
      "source": [
        "# # Downloading MURA dataset and unzipping the file (this one takes time)\n",
        "# from src.data_loader import download_dataset\n",
        "# from src.constants import DATASETS_FOLDER, MURA_DATASET\n",
        "# from src.helpers.utils import unzip_file\n",
        "# download_dataset(MURA_DATASET, DATASETS_FOLDER)\n",
        "# unzip_file(os.path.join(os.getcwd(), DATASETS_FOLDER, MURA_DATASET))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oLsfy94n50JC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VJZYJhy_1M9V"
      },
      "outputs": [],
      "source": [
        "# Enable faster convolutions\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# 1. Define Data Transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "valid_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Phpme_U51PRZ"
      },
      "outputs": [],
      "source": [
        "# 2. Define Dataset Class\n",
        "class MURABinaryDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        for _, row in self.data.iterrows():\n",
        "            study_path = os.path.join(root_dir, row['path'])\n",
        "            label = row['label']\n",
        "            self.image_paths.extend([os.path.join(study_path, img) for img in os.listdir(study_path) if img.endswith('.png')])\n",
        "            self.labels.extend([label] * len([img for img in os.listdir(study_path) if img.endswith('.png')]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, torch.tensor(label, dtype=torch.float32)\n",
        "        except Exception as e:\n",
        "            # Print warning and skip problematic file\n",
        "            print(f\"Warning: Skipping file {img_path} due to error: {e}\")\n",
        "            return None, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHaJFEsv1Rad",
        "outputId": "0a291386-2116-4429-d14c-a09f594de67c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 3. Load Datasets\n",
        "root_dir = '/content/drive/MyDrive/BoneawareAI/datasets/'\n",
        "train_dataset = MURABinaryDataset(\n",
        "    csv_file=os.path.join(root_dir, 'MURA-v1.1/train_labeled_studies.csv'),\n",
        "    root_dir=root_dir,\n",
        "    transform=train_transforms\n",
        ")\n",
        "valid_dataset = MURABinaryDataset(\n",
        "    csv_file=os.path.join(root_dir, 'MURA-v1.1/valid_labeled_studies.csv'),\n",
        "    root_dir=root_dir,\n",
        "    transform=valid_transforms\n",
        ")\n",
        "\n",
        "# 4. Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "B1uW7L0W1UfI"
      },
      "outputs": [],
      "source": [
        "# 5. Define Custom DenseNet\n",
        "class DenseLayer(nn.Module):\n",
        "    def __init__(self, in_channels, growth_rate, dropout_rate=0.2):\n",
        "        super(DenseLayer, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels, growth_rate, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.Dropout(dropout_rate)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        new_features = self.layer(x)\n",
        "        return torch.cat([x, new_features], dim=1)\n",
        "\n",
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, num_layers, in_channels, growth_rate, dropout_rate=0.2):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        layers = []\n",
        "        for _ in range(num_layers):\n",
        "            layers.append(DenseLayer(in_channels, growth_rate, dropout_rate))\n",
        "            in_channels += growth_rate\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class TransitionLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(TransitionLayer, self).__init__()\n",
        "        self.transition = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.transition(x)\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, num_blocks, num_layers_per_block, growth_rate, reduction, num_classes=1):\n",
        "        super(DenseNet, self).__init__()\n",
        "        self.growth_rate = growth_rate\n",
        "        in_channels = 2 * growth_rate\n",
        "\n",
        "        # Initial Convolution\n",
        "        self.init_conv = nn.Sequential(\n",
        "            nn.Conv2d(3, in_channels, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        # DenseBlocks with Transition Layers\n",
        "        blocks = []\n",
        "        for i in range(num_blocks):\n",
        "            blocks.append(DenseBlock(num_layers_per_block, in_channels, growth_rate))\n",
        "            in_channels += num_layers_per_block * growth_rate\n",
        "            if i != num_blocks - 1:  # No transition after the last block\n",
        "                out_channels = int(in_channels * reduction)\n",
        "                blocks.append(TransitionLayer(in_channels, out_channels))\n",
        "                in_channels = out_channels\n",
        "\n",
        "        self.features = nn.Sequential(*blocks)\n",
        "\n",
        "        # Classification Layer\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_channels, num_classes),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.init_conv(x)\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "brNI5fWs1YRj"
      },
      "outputs": [],
      "source": [
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Instantiate the DenseNet\n",
        "model = DenseNet(num_blocks=3, num_layers_per_block=4, growth_rate=32, reduction=0.5).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xXQBm2bK1ecb"
      },
      "outputs": [],
      "source": [
        "# 6. Define Loss, Optimizer, and Scheduler\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EeKszrlO1fYQ"
      },
      "outputs": [],
      "source": [
        "# 7. Training Function with Progress Monitoring\n",
        "def train_model(model, criterion, optimizer, train_loader, valid_loader, num_epochs=25):\n",
        "    best_model_wts = model.state_dict()\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "                loader = train_loader\n",
        "            else:\n",
        "                model.eval()\n",
        "                loader = valid_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            progress_bar = tqdm(enumerate(loader), total=len(loader), desc=f\"{phase} Progress\")\n",
        "\n",
        "            for i, (inputs, labels) in progress_bar:\n",
        "                # Skip batches with problematic files\n",
        "                inputs = [inp for inp in inputs if inp is not None]\n",
        "                labels = [lbl for lbl in labels if lbl is not None]\n",
        "\n",
        "                if len(inputs) == 0 or len(labels) == 0:\n",
        "                    continue\n",
        "\n",
        "                inputs = torch.stack(inputs).to(device)\n",
        "                labels = torch.tensor(labels).to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    outputs = outputs.squeeze()\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                preds = (outputs > 0.5).float()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels)\n",
        "\n",
        "                progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "            epoch_loss = running_loss / len(loader.dataset)\n",
        "            epoch_acc = running_corrects.double() / len(loader.dataset)\n",
        "\n",
        "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = model.state_dict()\n",
        "\n",
        "    print(f\"Best Validation Accuracy: {best_acc:.4f}\")\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ8rc6yt1jAN"
      },
      "outputs": [],
      "source": [
        "# 8. Train the Model\n",
        "model = train_model(model, criterion, optimizer, train_loader, valid_loader, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'densenet_mura.pth')\n",
        "\n",
        "# Load the model\n",
        "model.load_state_dict(torch.load('densenet_mura.pth'))\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "PnmnZGSHvaFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
        "            outputs = model(inputs).squeeze()\n",
        "            preds = (outputs > 0.5).float()\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds))\n",
        "    print(f\"AUC-ROC: {roc_auc_score(all_labels, all_preds):.4f}\")\n",
        "\n",
        "# Evaluate on validation set\n",
        "evaluate_model(model, valid_loader)\n"
      ],
      "metadata": {
        "id": "lRYc-ySYvdhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H9AKqsUGvhGK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}