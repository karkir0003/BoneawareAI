{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5CHWhyuzyfvZ"
   },
   "source": [
    "# BoneawareAI\n",
    "\n",
    "Authors: Karthik Subramanian, Charles Green, Sai Anurag Pichika, Saarang Prabhuram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFJ0ozK8yp3V"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0qyiSEXMe7v"
   },
   "source": [
    "### Load Extensions\n",
    "\n",
    "Before getting started we need to run some standard code to set up our environment. You'll need to execute this code again each time you start the notebook.\n",
    "\n",
    "First, run this cell to load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload) extension. This enables us to modify `.py` source files and reintegrate them into the notebook, ensuring a smooth editing and debugging experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HMh6Xv7hMe7w"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sopx83pHMe7w"
   },
   "source": [
    "### Google Colab Setup\n",
    "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
    "\n",
    "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fFVquhuCVrq",
    "outputId": "8aa28e32-4468-45a1-c9cd-4f6e5b16ca9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "It7_Rq3X4g3z",
    "outputId": "0ea26a2a-413d-47a7-ae68-ab96448301d4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/BoneawareAI'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "PROJECT_PATH = 'BoneawareAI'\n",
    "GOOGLE_DRIVE_PATH = f'/content/drive/MyDrive/{PROJECT_PATH}'\n",
    "os.chdir(GOOGLE_DRIVE_PATH)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "1w70X5avjfR1"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(GOOGLE_DRIVE_PATH) # this is important for the imports in the .py files to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TkDj-6n-EMYa",
    "outputId": "230c77cb-cffe-4ad9-daf9-ca1b7d1ced71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml==5.4.1 in c:\\users\\saara\\anaconda3\\envs\\boneaware-ai\\lib\\site-packages (5.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: boto3 in c:\\users\\saara\\anaconda3\\envs\\boneaware-ai\\lib\\site-packages (1.34.154)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.154 in c:\\users\\saara\\anaconda3\\envs\\boneaware-ai\\lib\\site-packages (from boto3) (1.34.154)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\saara\\anaconda3\\envs\\boneaware-ai\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\saara\\anaconda3\\envs\\boneaware-ai\\lib\\site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\saara\\anaconda3\\envs\\boneaware-ai\\lib\\site-packages (from botocore<1.35.0,>=1.34.154->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\saara\\anaconda3\\envs\\boneaware-ai\\lib\\site-packages (from botocore<1.35.0,>=1.34.154->boto3) (2.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\saara\\anaconda3\\envs\\boneaware-ai\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.154->boto3) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: configparser in c:\\users\\saara\\anaconda3\\envs\\boneaware-ai\\lib\\site-packages (5.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyyaml==5.4.1\n",
    "%pip install boto3\n",
    "%pip install configparser\n",
    "# %pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6-1yUtSMe7z"
   },
   "source": [
    "### Local Setup OR Google Drive\n",
    "Run the cell below regardless of whether you are using google drive or local setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ywxpbgWIMe7z",
    "outputId": "db3d004b-9674-4d52-90af-92b5a5f1661a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally.\n"
     ]
    }
   ],
   "source": [
    "# if running locally set GOOGLE PATH\n",
    "import sys\n",
    "isLocal = False\n",
    "if 'google.colab' in sys.modules:\n",
    "  print(f'Running in google colab. Our path is `{GOOGLE_DRIVE_PATH}`')\n",
    "else:\n",
    "  GOOGLE_DRIVE_PATH = '.'\n",
    "  print('Running locally.')\n",
    "  isLocal = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CJzQJ5FMe7z"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHlDJ5n1Me7z",
    "outputId": "5eebab23-7baf-4659-fb01-e1b4bf650e35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules added correctly, locally.\n"
     ]
    }
   ],
   "source": [
    "# RUN LOCALLY\n",
    "import sys\n",
    "if isLocal:\n",
    "    sys.path.append('../src')  # Add the 'src' folder to Python's module search path\n",
    "    sys.path.append('../datasets')  # Add the 'datasets' folder to Python's module search path\n",
    "    sys.path.append('../notebooks')  # Add the 'notebooks' folder to Python's module search path\n",
    "    print('Modules added correctly, locally.')\n",
    "else:\n",
    "    sys.path.append('src')  # Add the 'src' folder to Python's module search path\n",
    "    sys.path.append('datasets')  # Add the 'datasets' folder to Python's module search path\n",
    "    sys.path.append('notebooks')  # Add the 'notebooks' folder to Python's module search path\n",
    "    print('Modules added correctly on colab.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ny2_zskeMe70"
   },
   "outputs": [],
   "source": [
    "from image_utils import set_seed, MURADataset, load_data, confirm_images_and_labels, count_body_parts, count_positive_negative, count_body_parts_with_augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDEQTUPXMe70",
    "outputId": "400957ed-ada1-4cd5-cd80-a54b2661d02c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device = cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device = \" + device)\n",
    "if device == 'cpu':\n",
    "    print(\"WARNING: Using CPU will cause slower train times\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjzWXLZKMe70"
   },
   "source": [
    "#### Set Seed\n",
    "\n",
    "This is so the results can be duplicated, ensure that the seed is set in the image_utils.py file, if you want a random seed, import random and set a random number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9WpsZa4zMe70"
   },
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iU--YN8_Me71"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGVUtueX353J"
   },
   "source": [
    "## Data Preprocessing\n",
    "Get the dataset, perform data augmentation to get finalized MURA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIU_T5hM3-YD",
    "outputId": "beb560f7-22bf-4267-9ee0-603d302a968d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MURA-v1.1.zip already exists in datasets. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "# Downloading MURA dataset and unzipping the file (this one takes time)\n",
    "from data_loader import download_dataset\n",
    "from constants import DATASETS_FOLDER, MURA_DATASET\n",
    "from helpers.utils import unzip_file\n",
    "# Define the parent directory and dataset path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # Go to the parent directory\n",
    "datasets_folder = os.path.join(parent_dir, DATASETS_FOLDER)   # Define datasets folder in the parent directory\n",
    "dataset_path = os.path.join(datasets_folder, MURA_DATASET)    # Full path to the dataset file\n",
    "\n",
    "# Ensure the datasets folder exists\n",
    "os.makedirs(datasets_folder, exist_ok=True)\n",
    "\n",
    "# Check if the dataset is already downloaded\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(f\"{MURA_DATASET} not found in {DATASETS_FOLDER}. Downloading and extracting...\")\n",
    "    # Download and unzip the dataset\n",
    "    download_dataset(MURA_DATASET, datasets_folder)\n",
    "    # unzip_file(dataset_path)\n",
    "else:\n",
    "    print(f\"{MURA_DATASET} already exists in {DATASETS_FOLDER}. Skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "e1BtlQ_dMe71",
    "outputId": "19e0edbb-2e1c-4755-fa45-ea6005dda3f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 147232 training samples and 3197 validation samples.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_dir = \"../datasets/MURA-v1.1\"\n",
    "batch_size = 32\n",
    "\n",
    "# Load training and validation data\n",
    "train_loader, valid_loader = load_data(data_dir, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tQ8zvhHiMe71",
    "outputId": "b5c4bea1-07a7-4c89-9108-cab531004948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "Batch size: 32, Labels: tensor([0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 1, 0, 0, 0])\n",
      "Validation Data:\n",
      "Batch size: 32, Labels: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data:\")\n",
    "for batch in train_loader:\n",
    "    images, labels = batch\n",
    "    print(f\"Batch size: {len(images)}, Labels: {labels}\")\n",
    "    break\n",
    "\n",
    "# Test the validation DataLoader\n",
    "print(\"Validation Data:\")\n",
    "for images, labels in valid_loader:\n",
    "    print(f\"Batch size: {len(images)}, Labels: {labels}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9dxz7Q2vMe72",
    "outputId": "972455d6-907a-4227-ac60-5e86d5e7d410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the training dataset: 147232\n",
      "Number of samples in the validation dataset: 3197\n"
     ]
    }
   ],
   "source": [
    "# Access the datasets from the DataLoaders\n",
    "train_dataset = train_loader.dataset\n",
    "valid_dataset = valid_loader.dataset\n",
    "\n",
    "# Example: Print the length of the datasets\n",
    "print(f\"Number of samples in the training dataset: {len(train_dataset)}\")\n",
    "print(f\"Number of samples in the validation dataset: {len(valid_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MACZwlyXMe72"
   },
   "outputs": [],
   "source": [
    "#16 minutes to confirm on local, does not need to run as you can always use the dataset to confirm as well\n",
    "#confirm_images_and_labels(train_dataset, \"train\")\n",
    "#confirm_images_and_labels(valid_dataset, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "wKC-U9oAMe72",
    "outputId": "9372d8d1-edae-425b-aaa2-b0454538775e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset body part distribution:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BodyPart</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XR_WRIST</td>\n",
       "      <td>9752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>8379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XR_HAND</td>\n",
       "      <td>5543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XR_FINGER</td>\n",
       "      <td>5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XR_ELBOW</td>\n",
       "      <td>4931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XR_FOREARM</td>\n",
       "      <td>1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XR_HUMERUS</td>\n",
       "      <td>1272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BodyPart  Count\n",
       "0     XR_WRIST   9752\n",
       "1  XR_SHOULDER   8379\n",
       "2      XR_HAND   5543\n",
       "3    XR_FINGER   5106\n",
       "4     XR_ELBOW   4931\n",
       "5   XR_FOREARM   1825\n",
       "6   XR_HUMERUS   1272"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid dataset body part distribution:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BodyPart</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XR_WRIST</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XR_ELBOW</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XR_FINGER</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XR_HAND</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XR_FOREARM</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XR_HUMERUS</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BodyPart  Count\n",
       "0     XR_WRIST    659\n",
       "1  XR_SHOULDER    563\n",
       "2     XR_ELBOW    465\n",
       "3    XR_FINGER    461\n",
       "4      XR_HAND    460\n",
       "5   XR_FOREARM    301\n",
       "6   XR_HUMERUS    288"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_body_parts(train_dataset, \"train\")\n",
    "count_body_parts(valid_dataset, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "2LsFOtliMe72",
    "outputId": "a110d2ac-3c6e-44db-8329-71dc1f6796b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset body part distribution (with augmentations):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BodyPart</th>\n",
       "      <th>OriginalCount</th>\n",
       "      <th>AugmentedCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XR_WRIST</td>\n",
       "      <td>9752</td>\n",
       "      <td>39008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>8379</td>\n",
       "      <td>33516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XR_HAND</td>\n",
       "      <td>5543</td>\n",
       "      <td>22172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XR_FINGER</td>\n",
       "      <td>5106</td>\n",
       "      <td>20424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XR_ELBOW</td>\n",
       "      <td>4931</td>\n",
       "      <td>19724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XR_FOREARM</td>\n",
       "      <td>1825</td>\n",
       "      <td>7300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XR_HUMERUS</td>\n",
       "      <td>1272</td>\n",
       "      <td>5088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BodyPart  OriginalCount  AugmentedCount\n",
       "0     XR_WRIST           9752           39008\n",
       "1  XR_SHOULDER           8379           33516\n",
       "2      XR_HAND           5543           22172\n",
       "3    XR_FINGER           5106           20424\n",
       "4     XR_ELBOW           4931           19724\n",
       "5   XR_FOREARM           1825            7300\n",
       "6   XR_HUMERUS           1272            5088"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid dataset body part distribution (with augmentations):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BodyPart</th>\n",
       "      <th>OriginalCount</th>\n",
       "      <th>AugmentedCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XR_WRIST</td>\n",
       "      <td>659</td>\n",
       "      <td>2636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>563</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XR_ELBOW</td>\n",
       "      <td>465</td>\n",
       "      <td>1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XR_FINGER</td>\n",
       "      <td>461</td>\n",
       "      <td>1844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XR_HAND</td>\n",
       "      <td>460</td>\n",
       "      <td>1840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XR_FOREARM</td>\n",
       "      <td>301</td>\n",
       "      <td>1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XR_HUMERUS</td>\n",
       "      <td>288</td>\n",
       "      <td>1152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BodyPart  OriginalCount  AugmentedCount\n",
       "0     XR_WRIST            659            2636\n",
       "1  XR_SHOULDER            563            2252\n",
       "2     XR_ELBOW            465            1860\n",
       "3    XR_FINGER            461            1844\n",
       "4      XR_HAND            460            1840\n",
       "5   XR_FOREARM            301            1204\n",
       "6   XR_HUMERUS            288            1152"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage with 3 augmentations,  adjust the augmentations as needed\n",
    "count_body_parts_with_augmentations(train_dataset, \"train\", num_augmentations=3)\n",
    "count_body_parts_with_augmentations(valid_dataset, \"valid\", num_augmentations=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "h03i-7tEMe72",
    "outputId": "6163ef82-3dec-4834-89e6-90552f8c4cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset positive/negative distribution (with augmentations):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BodyPart</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>AugmentedNegative</th>\n",
       "      <th>AugmentedPositive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XR_ELBOW</td>\n",
       "      <td>2925</td>\n",
       "      <td>2006</td>\n",
       "      <td>11700</td>\n",
       "      <td>8024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XR_FINGER</td>\n",
       "      <td>3138</td>\n",
       "      <td>1968</td>\n",
       "      <td>12552</td>\n",
       "      <td>7872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XR_FOREARM</td>\n",
       "      <td>1164</td>\n",
       "      <td>661</td>\n",
       "      <td>4656</td>\n",
       "      <td>2644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XR_HAND</td>\n",
       "      <td>4059</td>\n",
       "      <td>1484</td>\n",
       "      <td>16236</td>\n",
       "      <td>5936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XR_HUMERUS</td>\n",
       "      <td>673</td>\n",
       "      <td>599</td>\n",
       "      <td>2692</td>\n",
       "      <td>2396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>4211</td>\n",
       "      <td>4168</td>\n",
       "      <td>16844</td>\n",
       "      <td>16672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XR_WRIST</td>\n",
       "      <td>5765</td>\n",
       "      <td>3987</td>\n",
       "      <td>23060</td>\n",
       "      <td>15948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BodyPart  Negative  Positive  AugmentedNegative  AugmentedPositive\n",
       "0     XR_ELBOW      2925      2006              11700               8024\n",
       "1    XR_FINGER      3138      1968              12552               7872\n",
       "2   XR_FOREARM      1164       661               4656               2644\n",
       "3      XR_HAND      4059      1484              16236               5936\n",
       "4   XR_HUMERUS       673       599               2692               2396\n",
       "5  XR_SHOULDER      4211      4168              16844              16672\n",
       "6     XR_WRIST      5765      3987              23060              15948"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid dataset positive/negative distribution (with augmentations):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BodyPart</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "      <th>AugmentedNegative</th>\n",
       "      <th>AugmentedPositive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XR_ELBOW</td>\n",
       "      <td>235</td>\n",
       "      <td>230</td>\n",
       "      <td>940</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XR_FINGER</td>\n",
       "      <td>214</td>\n",
       "      <td>247</td>\n",
       "      <td>856</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XR_FOREARM</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>600</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XR_HAND</td>\n",
       "      <td>271</td>\n",
       "      <td>189</td>\n",
       "      <td>1084</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XR_HUMERUS</td>\n",
       "      <td>148</td>\n",
       "      <td>140</td>\n",
       "      <td>592</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XR_SHOULDER</td>\n",
       "      <td>285</td>\n",
       "      <td>278</td>\n",
       "      <td>1140</td>\n",
       "      <td>1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XR_WRIST</td>\n",
       "      <td>364</td>\n",
       "      <td>295</td>\n",
       "      <td>1456</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BodyPart  Negative  Positive  AugmentedNegative  AugmentedPositive\n",
       "0     XR_ELBOW       235       230                940                920\n",
       "1    XR_FINGER       214       247                856                988\n",
       "2   XR_FOREARM       150       151                600                604\n",
       "3      XR_HAND       271       189               1084                756\n",
       "4   XR_HUMERUS       148       140                592                560\n",
       "5  XR_SHOULDER       285       278               1140               1112\n",
       "6     XR_WRIST       364       295               1456               1180"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count positive/negative cases in the training dataset (with 3 augmentations)\n",
    "count_positive_negative(train_dataset, \"train\", num_augmentations=3)\n",
    "\n",
    "# Count positive/negative cases in the validation dataset (with 3 augmentations)\n",
    "count_positive_negative(valid_dataset, \"valid\", num_augmentations=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgQmrLwHMe73"
   },
   "source": [
    "### Other Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ju8EWFkaMe73",
    "outputId": "52b82b02-d71b-4665-a7d8-dacbccc4c8b9"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlh28zGVMe73"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmACXssNX7MM"
   },
   "source": [
    "###DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "dH0qm718X_zy"
   },
   "outputs": [],
   "source": [
    "from models.densenet import DenseNet\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate the DenseNet\n",
    "model = DenseNet(num_blocks=3, num_layers_per_block=4, growth_rate=32, reduction=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "c02N-mzEYAVe"
   },
   "outputs": [],
   "source": [
    "# 6. Define Loss, Optimizer, and Scheduler\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "_S_08HiBYVVu"
   },
   "outputs": [],
   "source": [
    "# 7. Training Function with Progress Monitoring\n",
    "def train_model(model, criterion, optimizer, train_loader, valid_loader, num_epochs=25):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                loader = train_loader\n",
    "            else:\n",
    "                model.eval()\n",
    "                loader = valid_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            progress_bar = tqdm(enumerate(loader), total=len(loader), desc=f\"{phase} Progress\")\n",
    "\n",
    "            for i, (inputs, labels) in progress_bar:\n",
    "                # Skip batches with problematic files\n",
    "                try:\n",
    "                    # Ensure only valid inputs and labels are processed\n",
    "                    inputs = [inp for inp in inputs if inp is not None]\n",
    "                    labels = [lbl for lbl in labels if lbl is not None]\n",
    "\n",
    "                    # Skip if there are no valid inputs or labels after cleaning\n",
    "                    if len(inputs) == 0 or len(labels) == 0:\n",
    "                        continue\n",
    "\n",
    "                    inputs = torch.stack(inputs).to(device)\n",
    "                    labels = torch.tensor(labels).to(device).float()\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "                        outputs = outputs.squeeze()\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    preds = (outputs > 0.5).float()\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels)\n",
    "\n",
    "                    progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "                except Exception as e:\n",
    "                    # Print the error message and skip this batch\n",
    "                    print(f\"Skipping batch due to error: {e}\")\n",
    "                    continue  # Skip this batch and proceed to the next\n",
    "\n",
    "            epoch_loss = running_loss / len(loader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(loader.dataset)\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    print(f\"Best Validation Accuracy: {best_acc:.4f}\")\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SfL-ipYSYYa-"
   },
   "outputs": [],
   "source": [
    "# 8. Train the Model\n",
    "model = train_model(model, criterion, optimizer, train_loader, valid_loader, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "opU1Rx49Yajn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (init_conv): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (features): Sequential(\n",
       "    (0): DenseBlock(\n",
       "      (block): Sequential(\n",
       "        (0): DenseLayer(\n",
       "          (layer): Sequential(\n",
       "            (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): DenseLayer(\n",
       "          (layer): Sequential(\n",
       "            (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): DenseLayer(\n",
       "          (layer): Sequential(\n",
       "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): DenseLayer(\n",
       "          (layer): Sequential(\n",
       "            (0): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransitionLayer(\n",
       "      (transition): Sequential(\n",
       "        (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "    )\n",
       "    (2): DenseBlock(\n",
       "      (block): Sequential(\n",
       "        (0): DenseLayer(\n",
       "          (layer): Sequential(\n",
       "            (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): DenseLayer(\n",
       "          (layer): Sequential(\n",
       "            (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): DenseLayer(\n",
       "          (layer): Sequential(\n",
       "            (0): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(160, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): DenseLayer(\n",
       "          (layer): Sequential(\n",
       "            (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): TransitionLayer(\n",
       "      (transition): Sequential(\n",
       "        (0): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(224, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "    )\n",
       "    (4): DenseBlock(\n",
       "      (block): Sequential(\n",
       "        (0): DenseLayer(\n",
       "          (layer): Sequential(\n",
       "            (0): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(112, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): DenseLayer(\n",
       "          (layer): Sequential(\n",
       "            (0): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(144, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): DenseLayer(\n",
       "          (layer): Sequential(\n",
       "            (0): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(176, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): DenseLayer(\n",
       "          (layer): Sequential(\n",
       "            (0): BatchNorm2d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Conv2d(208, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (3): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=240, out_features=1, bias=True)\n",
       "    (3): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'densenet_mura.pth')\n",
    "\n",
    "# Load the model\n",
    "model.load_state_dict(torch.load('densenet_mura.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flaOATxgYcqT"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
    "            outputs = model(inputs).squeeze()\n",
    "            preds = (outputs > 0.5).float()\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "    print(f\"AUC-ROC: {roc_auc_score(all_labels, all_preds):.4f}\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "evaluate_model(model, valid_loader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "boneaware-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
