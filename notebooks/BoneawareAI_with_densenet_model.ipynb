{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CHWhyuzyfvZ"
      },
      "source": [
        "# BoneawareAI\n",
        "\n",
        "Authors: Karthik Subramanian, Charles Green, Sai Anurag Pichika, Saarang Prabhuram\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFJ0ozK8yp3V"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0qyiSEXMe7v"
      },
      "source": [
        "### Load Extensions\n",
        "\n",
        "Before getting started we need to run some standard code to set up our environment. You'll need to execute this code again each time you start the notebook.\n",
        "\n",
        "First, run this cell to load the [autoreload](https://ipython.readthedocs.io/en/stable/config/extensions/autoreload.html?highlight=autoreload) extension. This enables us to modify `.py` source files and reintegrate them into the notebook, ensuring a smooth editing and debugging experience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HMh6Xv7hMe7w"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sopx83pHMe7w"
      },
      "source": [
        "### Google Colab Setup\n",
        "Next we need to run a few commands to set up our environment on Google Colab. If you are running this notebook on a local machine you can skip this section.\n",
        "\n",
        "Run the following cell to mount your Google Drive. Follow the link, sign in to your Google account (the same account you used to store this notebook!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fFVquhuCVrq",
        "outputId": "8aa28e32-4468-45a1-c9cd-4f6e5b16ca9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "It7_Rq3X4g3z",
        "outputId": "0ea26a2a-413d-47a7-ae68-ab96448301d4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/BoneawareAI'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "PROJECT_PATH = 'BoneawareAI'\n",
        "GOOGLE_DRIVE_PATH = f'/content/drive/MyDrive/{PROJECT_PATH}'\n",
        "os.chdir(GOOGLE_DRIVE_PATH)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "1w70X5avjfR1"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(GOOGLE_DRIVE_PATH) # this is important for the imports in the .py files to work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkDj-6n-EMYa",
        "outputId": "230c77cb-cffe-4ad9-daf9-ca1b7d1ced71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyyaml==5.4.1\n",
            "  Downloading PyYAML-5.4.1.tar.gz (175 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[54 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m running egg_info\n",
            "  \u001b[31m   \u001b[0m writing lib3/PyYAML.egg-info/PKG-INFO\n",
            "  \u001b[31m   \u001b[0m writing dependency_links to lib3/PyYAML.egg-info/dependency_links.txt\n",
            "  \u001b[31m   \u001b[0m writing top-level names to lib3/PyYAML.egg-info/top_level.txt\n",
            "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
            "  \u001b[31m   \u001b[0m   File \"/Users/saianuragpichika/miniconda3/envs/cs7643-a2/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
            "  \u001b[31m   \u001b[0m     main()\n",
            "  \u001b[31m   \u001b[0m   File \"/Users/saianuragpichika/miniconda3/envs/cs7643-a2/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
            "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
            "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/Users/saianuragpichika/miniconda3/envs/cs7643-a2/lib/python3.12/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 118, in get_requires_for_build_wheel\n",
            "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
            "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/zp/kl26m30125x90cpkt8s_899r0000gn/T/pip-build-env-a8molf1s/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 334, in get_requires_for_build_wheel\n",
            "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=[])\n",
            "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/zp/kl26m30125x90cpkt8s_899r0000gn/T/pip-build-env-a8molf1s/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 304, in _get_build_requires\n",
            "  \u001b[31m   \u001b[0m     self.run_setup()\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/zp/kl26m30125x90cpkt8s_899r0000gn/T/pip-build-env-a8molf1s/overlay/lib/python3.12/site-packages/setuptools/build_meta.py\", line 320, in run_setup\n",
            "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
            "  \u001b[31m   \u001b[0m   File \"<string>\", line 271, in <module>\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/zp/kl26m30125x90cpkt8s_899r0000gn/T/pip-build-env-a8molf1s/overlay/lib/python3.12/site-packages/setuptools/__init__.py\", line 117, in setup\n",
            "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
            "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/zp/kl26m30125x90cpkt8s_899r0000gn/T/pip-build-env-a8molf1s/overlay/lib/python3.12/site-packages/setuptools/_distutils/core.py\", line 183, in setup\n",
            "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
            "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/zp/kl26m30125x90cpkt8s_899r0000gn/T/pip-build-env-a8molf1s/overlay/lib/python3.12/site-packages/setuptools/_distutils/core.py\", line 199, in run_commands\n",
            "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/zp/kl26m30125x90cpkt8s_899r0000gn/T/pip-build-env-a8molf1s/overlay/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 954, in run_commands\n",
            "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/zp/kl26m30125x90cpkt8s_899r0000gn/T/pip-build-env-a8molf1s/overlay/lib/python3.12/site-packages/setuptools/dist.py\", line 995, in run_command\n",
            "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/zp/kl26m30125x90cpkt8s_899r0000gn/T/pip-build-env-a8molf1s/overlay/lib/python3.12/site-packages/setuptools/_distutils/dist.py\", line 973, in run_command\n",
            "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/zp/kl26m30125x90cpkt8s_899r0000gn/T/pip-build-env-a8molf1s/overlay/lib/python3.12/site-packages/setuptools/command/egg_info.py\", line 313, in run\n",
            "  \u001b[31m   \u001b[0m     self.find_sources()\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/zp/kl26m30125x90cpkt8s_899r0000gn/T/pip-build-env-a8molf1s/overlay/lib/python3.12/site-packages/setuptools/command/egg_info.py\", line 321, in find_sources\n",
            "  \u001b[31m   \u001b[0m     mm.run()\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/zp/kl26m30125x90cpkt8s_899r0000gn/T/pip-build-env-a8molf1s/overlay/lib/python3.12/site-packages/setuptools/command/egg_info.py\", line 544, in run\n",
            "  \u001b[31m   \u001b[0m     self.add_defaults()\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/zp/kl26m30125x90cpkt8s_899r0000gn/T/pip-build-env-a8molf1s/overlay/lib/python3.12/site-packages/setuptools/command/egg_info.py\", line 582, in add_defaults\n",
            "  \u001b[31m   \u001b[0m     sdist.add_defaults(self)\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/zp/kl26m30125x90cpkt8s_899r0000gn/T/pip-build-env-a8molf1s/overlay/lib/python3.12/site-packages/setuptools/command/sdist.py\", line 109, in add_defaults\n",
            "  \u001b[31m   \u001b[0m     super().add_defaults()\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/zp/kl26m30125x90cpkt8s_899r0000gn/T/pip-build-env-a8molf1s/overlay/lib/python3.12/site-packages/setuptools/_distutils/command/sdist.py\", line 238, in add_defaults\n",
            "  \u001b[31m   \u001b[0m     self._add_defaults_ext()\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/zp/kl26m30125x90cpkt8s_899r0000gn/T/pip-build-env-a8molf1s/overlay/lib/python3.12/site-packages/setuptools/_distutils/command/sdist.py\", line 323, in _add_defaults_ext\n",
            "  \u001b[31m   \u001b[0m     self.filelist.extend(build_ext.get_source_files())\n",
            "  \u001b[31m   \u001b[0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  \u001b[31m   \u001b[0m   File \"<string>\", line 201, in get_source_files\n",
            "  \u001b[31m   \u001b[0m   File \"/private/var/folders/zp/kl26m30125x90cpkt8s_899r0000gn/T/pip-build-env-a8molf1s/overlay/lib/python3.12/site-packages/setuptools/_distutils/cmd.py\", line 107, in __getattr__\n",
            "  \u001b[31m   \u001b[0m     raise AttributeError(attr)\n",
            "  \u001b[31m   \u001b[0m AttributeError: cython_sources\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.35.66-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting botocore<1.36.0,>=1.35.66 (from boto3)\n",
            "  Downloading botocore-1.35.66-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/saianuragpichika/miniconda3/envs/cs7643-a2/lib/python3.12/site-packages (from botocore<1.36.0,>=1.35.66->boto3) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/saianuragpichika/miniconda3/envs/cs7643-a2/lib/python3.12/site-packages (from botocore<1.36.0,>=1.35.66->boto3) (2.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/saianuragpichika/miniconda3/envs/cs7643-a2/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.66->boto3) (1.16.0)\n",
            "Downloading boto3-1.35.66-py3-none-any.whl (139 kB)\n",
            "Downloading botocore-1.35.66-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.35.66 botocore-1.35.66 jmespath-1.0.1 s3transfer-0.10.4\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting configparser\n",
            "  Downloading configparser-7.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Downloading configparser-7.1.0-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: configparser\n",
            "Successfully installed configparser-7.1.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pyyaml==5.4.1\n",
        "%pip install boto3\n",
        "%pip install configparser\n",
        "# %pip install torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6-1yUtSMe7z"
      },
      "source": [
        "### Local Setup OR Google Drive\n",
        "Run the cell below regardless of whether you are using google drive or local setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywxpbgWIMe7z",
        "outputId": "db3d004b-9674-4d52-90af-92b5a5f1661a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running locally.\n"
          ]
        }
      ],
      "source": [
        "# if running locally set GOOGLE PATH\n",
        "import sys\n",
        "isLocal = False\n",
        "if 'google.colab' in sys.modules:\n",
        "  print(f'Running in google colab. Our path is `{GOOGLE_DRIVE_PATH}`')\n",
        "else:\n",
        "  GOOGLE_DRIVE_PATH = '.'\n",
        "  print('Running locally.')\n",
        "  isLocal = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CJzQJ5FMe7z"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHlDJ5n1Me7z",
        "outputId": "5eebab23-7baf-4659-fb01-e1b4bf650e35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modules added correctly, locally.\n"
          ]
        }
      ],
      "source": [
        "# RUN LOCALLY\n",
        "import sys\n",
        "if isLocal:\n",
        "    sys.path.append('../src')  # Add the 'src' folder to Python's module search path\n",
        "    sys.path.append('../datasets')  # Add the 'datasets' folder to Python's module search path\n",
        "    sys.path.append('../notebooks')  # Add the 'notebooks' folder to Python's module search path\n",
        "    print('Modules added correctly, locally.')\n",
        "else:\n",
        "    sys.path.append('src')  # Add the 'src' folder to Python's module search path\n",
        "    sys.path.append('datasets')  # Add the 'datasets' folder to Python's module search path\n",
        "    sys.path.append('notebooks')  # Add the 'notebooks' folder to Python's module search path\n",
        "    print('Modules added correctly on colab.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ny2_zskeMe70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "  Downloading pandas-2.2.3-cp312-cp312-macosx_10_9_x86_64.whl.metadata (89 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /Users/saianuragpichika/miniconda3/envs/cs7643-a2/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/saianuragpichika/miniconda3/envs/cs7643-a2/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/saianuragpichika/miniconda3/envs/cs7643-a2/lib/python3.12/site-packages (from pandas) (2024.1)\n",
            "Collecting tzdata>=2022.7 (from pandas)\n",
            "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /Users/saianuragpichika/miniconda3/envs/cs7643-a2/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading pandas-2.2.3-cp312-cp312-macosx_10_9_x86_64.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
            "Installing collected packages: tzdata, pandas\n",
            "Successfully installed pandas-2.2.3 tzdata-2024.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "from image_utils import set_seed, MURADataset, load_data, confirm_images_and_labels, count_body_parts, count_positive_negative, count_body_parts_with_augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDEQTUPXMe70",
        "outputId": "400957ed-ada1-4cd5-cd80-a54b2661d02c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device = mps\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "device = 'mps' if torch.backends.mps.is_available() else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device = \" + device)\n",
        "if device == 'cpu':\n",
        "    print(\"WARNING: Using CPU will cause slower train times\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjzWXLZKMe70"
      },
      "source": [
        "#### Set Seed\n",
        "\n",
        "This is so the results can be duplicated, ensure that the seed is set in the image_utils.py file, if you want a random seed, import random and set a random number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "9WpsZa4zMe70"
      },
      "outputs": [],
      "source": [
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iU--YN8_Me71"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import nn, optim\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGVUtueX353J"
      },
      "source": [
        "## Data Preprocessing\n",
        "Get the dataset, perform data augmentation to get finalized MURA dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIU_T5hM3-YD",
        "outputId": "beb560f7-22bf-4267-9ee0-603d302a968d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MURA-v1.1.zip not found in datasets. Downloading and extracting...\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "Config file not found at /Users/saianuragpichika/Desktop/OMSCS/Fall 2024/Deep Learning/project/BoneawareAI/config.ini",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMURA_DATASET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASETS_FOLDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Downloading and extracting...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Download and unzip the dataset\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     download_dataset(MURA_DATASET, datasets_folder)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# unzip_file(dataset_path)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMURA_DATASET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already exists in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASETS_FOLDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Skipping download.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/Desktop/OMSCS/Fall 2024/Deep Learning/project/BoneawareAI/notebooks/../src/data_loader.py:9\u001b[0m, in \u001b[0;36mdownload_dataset\u001b[0;34m(file, output_folder)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_dataset\u001b[39m(file, output_folder):\n\u001b[0;32m----> 9\u001b[0m     download_file_from_s3(BONEAWAREAI_S3_BUCKET, file, output_folder)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mis_zipfile(file):\n\u001b[1;32m     12\u001b[0m         unzip_file(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, file))\n",
            "File \u001b[0;32m~/Desktop/OMSCS/Fall 2024/Deep Learning/project/BoneawareAI/notebooks/../src/helpers/aws_utils.py:57\u001b[0m, in \u001b[0;36mdownload_file_from_s3\u001b[0;34m(bucket_name, file_key, output_folder)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03mDownload a file from S3 using the provided temporary credentials.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m- output_folder: where to download the file to\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Get temporary credentials\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m credentials \u001b[38;5;241m=\u001b[39m assume_role(\n\u001b[1;32m     58\u001b[0m     BONEAWAREAI_DATA_ACCESS_ROLE, BONEAWAREAI_DATA_ACCESS_SESSION\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Use the temporary credentials to create an S3 client\u001b[39;00m\n\u001b[1;32m     62\u001b[0m s3_client \u001b[38;5;241m=\u001b[39m boto3\u001b[38;5;241m.\u001b[39mclient(\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     64\u001b[0m     aws_access_key_id\u001b[38;5;241m=\u001b[39mcredentials[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessKeyId\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     65\u001b[0m     aws_secret_access_key\u001b[38;5;241m=\u001b[39mcredentials[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSecretAccessKey\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     66\u001b[0m     aws_session_token\u001b[38;5;241m=\u001b[39mcredentials[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSessionToken\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     67\u001b[0m )\n",
            "File \u001b[0;32m~/Desktop/OMSCS/Fall 2024/Deep Learning/project/BoneawareAI/notebooks/../src/helpers/aws_utils.py:29\u001b[0m, in \u001b[0;36massume_role\u001b[0;34m(role_arn, session_name, duration)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massume_role\u001b[39m(role_arn, session_name, duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3600\u001b[39m):\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    Assume an IAM role and get temporary credentials.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    Note duration in seconds\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     aws_access_key_id, aws_secret_access_key \u001b[38;5;241m=\u001b[39m get_aws_credentials()\n\u001b[1;32m     30\u001b[0m     sts_client \u001b[38;5;241m=\u001b[39m boto3\u001b[38;5;241m.\u001b[39mclient(\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msts\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m         aws_access_key_id\u001b[38;5;241m=\u001b[39maws_access_key_id,\n\u001b[1;32m     33\u001b[0m         aws_secret_access_key\u001b[38;5;241m=\u001b[39maws_secret_access_key,\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/Desktop/OMSCS/Fall 2024/Deep Learning/project/BoneawareAI/notebooks/../src/helpers/aws_utils.py:15\u001b[0m, in \u001b[0;36mget_aws_credentials\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m config_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(main_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.ini\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(config_path):\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig file not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m config\u001b[38;5;241m.\u001b[39mread(config_path)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m config:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Config file not found at /Users/saianuragpichika/Desktop/OMSCS/Fall 2024/Deep Learning/project/BoneawareAI/config.ini"
          ]
        }
      ],
      "source": [
        "# Downloading MURA dataset and unzipping the file (this one takes time)\n",
        "from data_loader import download_dataset\n",
        "from constants import DATASETS_FOLDER, MURA_DATASET\n",
        "from helpers.utils import unzip_file\n",
        "# Define the parent directory and dataset path\n",
        "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # Go to the parent directory\n",
        "datasets_folder = os.path.join(parent_dir, DATASETS_FOLDER)   # Define datasets folder in the parent directory\n",
        "dataset_path = os.path.join(datasets_folder, MURA_DATASET)    # Full path to the dataset file\n",
        "\n",
        "# Ensure the datasets folder exists\n",
        "os.makedirs(datasets_folder, exist_ok=True)\n",
        "\n",
        "# Check if the dataset is already downloaded\n",
        "if not os.path.exists(dataset_path):\n",
        "    print(f\"{MURA_DATASET} not found in {DATASETS_FOLDER}. Downloading and extracting...\")\n",
        "    # Download and unzip the dataset\n",
        "    download_dataset(MURA_DATASET, datasets_folder)\n",
        "    # unzip_file(dataset_path)\n",
        "else:\n",
        "    print(f\"{MURA_DATASET} already exists in {DATASETS_FOLDER}. Skipping download.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "e1BtlQ_dMe71",
        "outputId": "19e0edbb-2e1c-4755-fa45-ea6005dda3f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 147232 training samples and 3197 validation samples.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data_dir = \"../datasets/MURA-v1.1\"\n",
        "batch_size = 32\n",
        "\n",
        "# Load training and validation data\n",
        "train_loader, valid_loader = load_data(data_dir, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tQ8zvhHiMe71",
        "outputId": "b5c4bea1-07a7-4c89-9108-cab531004948"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Data:\n",
            "Batch size: 32, Labels: tensor([1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
            "        0, 0, 0, 0, 1, 1, 0, 1])\n"
          ]
        }
      ],
      "source": [
        "print(\"Training Data:\")\n",
        "for batch in train_loader:\n",
        "    images, labels = batch\n",
        "    print(f\"Batch size: {len(images)}, Labels: {labels}\")\n",
        "    break\n",
        "\n",
        "# Test the validation DataLoader\n",
        "print(\"Validation Data:\")\n",
        "for images, labels in valid_loader:\n",
        "    print(f\"Batch size: {len(images)}, Labels: {labels}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dxz7Q2vMe72",
        "outputId": "972455d6-907a-4227-ac60-5e86d5e7d410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples in the training dataset: 147232\n",
            "Number of samples in the validation dataset: 3197\n"
          ]
        }
      ],
      "source": [
        "# Access the datasets from the DataLoaders\n",
        "train_dataset = train_loader.dataset\n",
        "valid_dataset = valid_loader.dataset\n",
        "\n",
        "# Example: Print the length of the datasets\n",
        "print(f\"Number of samples in the training dataset: {len(train_dataset)}\")\n",
        "print(f\"Number of samples in the validation dataset: {len(valid_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MACZwlyXMe72"
      },
      "outputs": [],
      "source": [
        "#16 minutes to confirm on local, does not need to run as you can always use the dataset to confirm as well\n",
        "#confirm_images_and_labels(train_dataset, \"train\")\n",
        "#confirm_images_and_labels(valid_dataset, \"valid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKC-U9oAMe72",
        "outputId": "9372d8d1-edae-425b-aaa2-b0454538775e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset body part distribution:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BodyPart</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XR_WRIST</td>\n",
              "      <td>9752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XR_SHOULDER</td>\n",
              "      <td>8379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XR_HAND</td>\n",
              "      <td>5543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>XR_FINGER</td>\n",
              "      <td>5106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XR_ELBOW</td>\n",
              "      <td>4931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>XR_FOREARM</td>\n",
              "      <td>1825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>XR_HUMERUS</td>\n",
              "      <td>1272</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      BodyPart  Count\n",
              "0     XR_WRIST   9752\n",
              "1  XR_SHOULDER   8379\n",
              "2      XR_HAND   5543\n",
              "3    XR_FINGER   5106\n",
              "4     XR_ELBOW   4931\n",
              "5   XR_FOREARM   1825\n",
              "6   XR_HUMERUS   1272"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid dataset body part distribution:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BodyPart</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XR_WRIST</td>\n",
              "      <td>659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XR_SHOULDER</td>\n",
              "      <td>563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XR_ELBOW</td>\n",
              "      <td>465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>XR_FINGER</td>\n",
              "      <td>461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XR_HAND</td>\n",
              "      <td>460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>XR_FOREARM</td>\n",
              "      <td>301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>XR_HUMERUS</td>\n",
              "      <td>288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      BodyPart  Count\n",
              "0     XR_WRIST    659\n",
              "1  XR_SHOULDER    563\n",
              "2     XR_ELBOW    465\n",
              "3    XR_FINGER    461\n",
              "4      XR_HAND    460\n",
              "5   XR_FOREARM    301\n",
              "6   XR_HUMERUS    288"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "count_body_parts(train_dataset, \"train\")\n",
        "count_body_parts(valid_dataset, \"valid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LsFOtliMe72",
        "outputId": "a110d2ac-3c6e-44db-8329-71dc1f6796b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset body part distribution (with augmentations):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BodyPart</th>\n",
              "      <th>OriginalCount</th>\n",
              "      <th>AugmentedCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XR_WRIST</td>\n",
              "      <td>9752</td>\n",
              "      <td>39008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XR_SHOULDER</td>\n",
              "      <td>8379</td>\n",
              "      <td>33516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XR_HAND</td>\n",
              "      <td>5543</td>\n",
              "      <td>22172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>XR_FINGER</td>\n",
              "      <td>5106</td>\n",
              "      <td>20424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XR_ELBOW</td>\n",
              "      <td>4931</td>\n",
              "      <td>19724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>XR_FOREARM</td>\n",
              "      <td>1825</td>\n",
              "      <td>7300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>XR_HUMERUS</td>\n",
              "      <td>1272</td>\n",
              "      <td>5088</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      BodyPart  OriginalCount  AugmentedCount\n",
              "0     XR_WRIST           9752           39008\n",
              "1  XR_SHOULDER           8379           33516\n",
              "2      XR_HAND           5543           22172\n",
              "3    XR_FINGER           5106           20424\n",
              "4     XR_ELBOW           4931           19724\n",
              "5   XR_FOREARM           1825            7300\n",
              "6   XR_HUMERUS           1272            5088"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid dataset body part distribution (with augmentations):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BodyPart</th>\n",
              "      <th>OriginalCount</th>\n",
              "      <th>AugmentedCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XR_WRIST</td>\n",
              "      <td>659</td>\n",
              "      <td>2636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XR_SHOULDER</td>\n",
              "      <td>563</td>\n",
              "      <td>2252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XR_ELBOW</td>\n",
              "      <td>465</td>\n",
              "      <td>1860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>XR_FINGER</td>\n",
              "      <td>461</td>\n",
              "      <td>1844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XR_HAND</td>\n",
              "      <td>460</td>\n",
              "      <td>1840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>XR_FOREARM</td>\n",
              "      <td>301</td>\n",
              "      <td>1204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>XR_HUMERUS</td>\n",
              "      <td>288</td>\n",
              "      <td>1152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      BodyPart  OriginalCount  AugmentedCount\n",
              "0     XR_WRIST            659            2636\n",
              "1  XR_SHOULDER            563            2252\n",
              "2     XR_ELBOW            465            1860\n",
              "3    XR_FINGER            461            1844\n",
              "4      XR_HAND            460            1840\n",
              "5   XR_FOREARM            301            1204\n",
              "6   XR_HUMERUS            288            1152"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Example usage with 3 augmentations,  adjust the augmentations as needed\n",
        "count_body_parts_with_augmentations(train_dataset, \"train\", num_augmentations=3)\n",
        "count_body_parts_with_augmentations(valid_dataset, \"valid\", num_augmentations=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h03i-7tEMe72",
        "outputId": "6163ef82-3dec-4834-89e6-90552f8c4cff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset positive/negative distribution (with augmentations):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BodyPart</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Positive</th>\n",
              "      <th>AugmentedNegative</th>\n",
              "      <th>AugmentedPositive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XR_ELBOW</td>\n",
              "      <td>2925</td>\n",
              "      <td>2006</td>\n",
              "      <td>11700</td>\n",
              "      <td>8024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XR_FINGER</td>\n",
              "      <td>3138</td>\n",
              "      <td>1968</td>\n",
              "      <td>12552</td>\n",
              "      <td>7872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XR_FOREARM</td>\n",
              "      <td>1164</td>\n",
              "      <td>661</td>\n",
              "      <td>4656</td>\n",
              "      <td>2644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>XR_HAND</td>\n",
              "      <td>4059</td>\n",
              "      <td>1484</td>\n",
              "      <td>16236</td>\n",
              "      <td>5936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XR_HUMERUS</td>\n",
              "      <td>673</td>\n",
              "      <td>599</td>\n",
              "      <td>2692</td>\n",
              "      <td>2396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>XR_SHOULDER</td>\n",
              "      <td>4211</td>\n",
              "      <td>4168</td>\n",
              "      <td>16844</td>\n",
              "      <td>16672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>XR_WRIST</td>\n",
              "      <td>5765</td>\n",
              "      <td>3987</td>\n",
              "      <td>23060</td>\n",
              "      <td>15948</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      BodyPart  Negative  Positive  AugmentedNegative  AugmentedPositive\n",
              "0     XR_ELBOW      2925      2006              11700               8024\n",
              "1    XR_FINGER      3138      1968              12552               7872\n",
              "2   XR_FOREARM      1164       661               4656               2644\n",
              "3      XR_HAND      4059      1484              16236               5936\n",
              "4   XR_HUMERUS       673       599               2692               2396\n",
              "5  XR_SHOULDER      4211      4168              16844              16672\n",
              "6     XR_WRIST      5765      3987              23060              15948"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid dataset positive/negative distribution (with augmentations):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BodyPart</th>\n",
              "      <th>Negative</th>\n",
              "      <th>Positive</th>\n",
              "      <th>AugmentedNegative</th>\n",
              "      <th>AugmentedPositive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XR_ELBOW</td>\n",
              "      <td>235</td>\n",
              "      <td>230</td>\n",
              "      <td>940</td>\n",
              "      <td>920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XR_FINGER</td>\n",
              "      <td>214</td>\n",
              "      <td>247</td>\n",
              "      <td>856</td>\n",
              "      <td>988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XR_FOREARM</td>\n",
              "      <td>150</td>\n",
              "      <td>151</td>\n",
              "      <td>600</td>\n",
              "      <td>604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>XR_HAND</td>\n",
              "      <td>271</td>\n",
              "      <td>189</td>\n",
              "      <td>1084</td>\n",
              "      <td>756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>XR_HUMERUS</td>\n",
              "      <td>148</td>\n",
              "      <td>140</td>\n",
              "      <td>592</td>\n",
              "      <td>560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>XR_SHOULDER</td>\n",
              "      <td>285</td>\n",
              "      <td>278</td>\n",
              "      <td>1140</td>\n",
              "      <td>1112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>XR_WRIST</td>\n",
              "      <td>364</td>\n",
              "      <td>295</td>\n",
              "      <td>1456</td>\n",
              "      <td>1180</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      BodyPart  Negative  Positive  AugmentedNegative  AugmentedPositive\n",
              "0     XR_ELBOW       235       230                940                920\n",
              "1    XR_FINGER       214       247                856                988\n",
              "2   XR_FOREARM       150       151                600                604\n",
              "3      XR_HAND       271       189               1084                756\n",
              "4   XR_HUMERUS       148       140                592                560\n",
              "5  XR_SHOULDER       285       278               1140               1112\n",
              "6     XR_WRIST       364       295               1456               1180"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Count positive/negative cases in the training dataset (with 3 augmentations)\n",
        "count_positive_negative(train_dataset, \"train\", num_augmentations=3)\n",
        "\n",
        "# Count positive/negative cases in the validation dataset (with 3 augmentations)\n",
        "count_positive_negative(valid_dataset, \"valid\", num_augmentations=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgQmrLwHMe73"
      },
      "source": [
        "### Other Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju8EWFkaMe73",
        "outputId": "52b82b02-d71b-4665-a7d8-dacbccc4c8b9"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlh28zGVMe73"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmACXssNX7MM"
      },
      "source": [
        "###DenseNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6mD5-fPX6r1"
      },
      "outputs": [],
      "source": [
        "# 5. Define Custom DenseNet\n",
        "class DenseLayer(nn.Module):\n",
        "    def __init__(self, in_channels, growth_rate, dropout_rate=0.2):\n",
        "        super(DenseLayer, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels, growth_rate, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.Dropout(dropout_rate)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        new_features = self.layer(x)\n",
        "        return torch.cat([x, new_features], dim=1)\n",
        "\n",
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, num_layers, in_channels, growth_rate, dropout_rate=0.2):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        layers = []\n",
        "        for _ in range(num_layers):\n",
        "            layers.append(DenseLayer(in_channels, growth_rate, dropout_rate))\n",
        "            in_channels += growth_rate\n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class TransitionLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(TransitionLayer, self).__init__()\n",
        "        self.transition = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.transition(x)\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, num_blocks, num_layers_per_block, growth_rate, reduction, num_classes=1):\n",
        "        super(DenseNet, self).__init__()\n",
        "        self.growth_rate = growth_rate\n",
        "        in_channels = 2 * growth_rate\n",
        "\n",
        "        # Initial Convolution\n",
        "        self.init_conv = nn.Sequential(\n",
        "            nn.Conv2d(3, in_channels, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        # DenseBlocks with Transition Layers\n",
        "        blocks = []\n",
        "        for i in range(num_blocks):\n",
        "            blocks.append(DenseBlock(num_layers_per_block, in_channels, growth_rate))\n",
        "            in_channels += num_layers_per_block * growth_rate\n",
        "            if i != num_blocks - 1:  # No transition after the last block\n",
        "                out_channels = int(in_channels * reduction)\n",
        "                blocks.append(TransitionLayer(in_channels, out_channels))\n",
        "                in_channels = out_channels\n",
        "\n",
        "        self.features = nn.Sequential(*blocks)\n",
        "\n",
        "        # Classification Layer\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_channels, num_classes),\n",
        "            nn.Softmax()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.init_conv(x)\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dH0qm718X_zy"
      },
      "outputs": [],
      "source": [
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Instantiate the DenseNet\n",
        "model = DenseNet(num_blocks=3, num_layers_per_block=4, growth_rate=32, reduction=0.5).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c02N-mzEYAVe"
      },
      "outputs": [],
      "source": [
        "# 6. Define Loss, Optimizer, and Scheduler\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_S_08HiBYVVu"
      },
      "outputs": [],
      "source": [
        "# 7. Training Function with Progress Monitoring\n",
        "def train_model(model, criterion, optimizer, train_loader, valid_loader, num_epochs=25):\n",
        "    best_model_wts = model.state_dict()\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "                loader = train_loader\n",
        "            else:\n",
        "                model.eval()\n",
        "                loader = valid_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            progress_bar = tqdm(enumerate(loader), total=len(loader), desc=f\"{phase} Progress\")\n",
        "\n",
        "            for i, (inputs, labels) in progress_bar:\n",
        "                # Skip batches with problematic files\n",
        "                try:\n",
        "                    # Ensure only valid inputs and labels are processed\n",
        "                    inputs = [inp for inp in inputs if inp is not None]\n",
        "                    labels = [lbl for lbl in labels if lbl is not None]\n",
        "\n",
        "                    # Skip if there are no valid inputs or labels after cleaning\n",
        "                    if len(inputs) == 0 or len(labels) == 0:\n",
        "                        continue\n",
        "\n",
        "                    inputs = torch.stack(inputs).to(device)\n",
        "                    labels = torch.tensor(labels).to(device).float()\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)\n",
        "                        outputs = outputs.squeeze()\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    preds = (outputs > 0.5).float()\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels)\n",
        "\n",
        "                    progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "                except Exception as e:\n",
        "                    # Print the error message and skip this batch\n",
        "                    print(f\"Skipping batch due to error: {e}\")\n",
        "                    continue  # Skip this batch and proceed to the next\n",
        "\n",
        "            epoch_loss = running_loss / len(loader.dataset)\n",
        "            epoch_acc = running_corrects.double() / len(loader.dataset)\n",
        "\n",
        "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "            if phase == 'valid' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = model.state_dict()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    print(f\"Best Validation Accuracy: {best_acc:.4f}\")\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfL-ipYSYYa-"
      },
      "outputs": [],
      "source": [
        "# 8. Train the Model\n",
        "model = train_model(model, criterion, optimizer, train_loader, valid_loader, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opU1Rx49Yajn"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'densenet_mura.pth')\n",
        "\n",
        "# Load the model\n",
        "model.load_state_dict(torch.load('densenet_mura.pth'))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flaOATxgYcqT"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.float().to(device)\n",
        "            outputs = model(inputs).squeeze()\n",
        "            preds = (outputs > 0.5).float()\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(all_labels, all_preds))\n",
        "    print(f\"AUC-ROC: {roc_auc_score(all_labels, all_preds):.4f}\")\n",
        "\n",
        "# Evaluate on validation set\n",
        "evaluate_model(model, valid_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cs7643-a2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
